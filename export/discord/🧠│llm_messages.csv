Author,Content,Timestamp
Nix,"At some point I will have to check out the new Gemma 2 models as they are EXTREMELY high on the LMSYS leaderboard, I am sure they will go down a few ranks as more votes are in, but they are starting very high, like Gemma-2-27B being close to Yi-Large, a 100B+ model? Or even crazier is Gemma-2-9B being above multiple older GPT-4 models?

I only use benchmarks as a guide to see what model is doing well and such, but those small models performing as good as models many times their size is just a bit suspicious to me, and I feel that they might be really good at reasoning and such, but might suffer from a lack of knowledge possibly in being such small sizes, like how even though LLaMA-3-8B is above a ton of powerful models and trained on 15T tokens, it suffers a lot when it comes to its knowledge just based on its size. I am very curious how they perform because from benchmarks, Gemma-2-27B underperforms a little bit on most when compared to Yi-1.5-34B, but it is extremely high on LMSYS so things just seem off with that. Guess I will have to try them out to see how they actually perform soon enough in the real world.

It seems they trained the 9B using the 27B model with knowledge distillation which makes sense for it being able to be quite powerful for its size and the benchmarks support it, but still very curious about the ranking of both models and the performance of the 27B model.",2024-06-27 18:27:24.565000+00:00
Nuo Ma @01.ai,"Yup, kinda amazing results, but haven’t got a chance to test it out myself, need some time to prove",2024-06-28 13:50:39.891000+00:00
Nuo Ma @01.ai,,2024-06-28 13:50:51.072000+00:00
Nuo Ma @01.ai,"I wouldn’t say its a terrible thing to do, lmsys is always about human preference anyway",2024-06-28 13:51:21.919000+00:00
Nix,"Oh wow! Tuning to chatbotarena would definitely help in making the model align more to conversational abilities so it makes sense.

I got to test it myself to see it's performance based on other models, but seeing other people thoughts about the model, it's understanding and reasoning capabilities are amazing and the responses are great too, but for others it seems to be a bit underwhelming, which might be from if the tuning of the model is not lining up with the preferences seen on LMSYS for that user, and seen a bunch of people complain about the context window only being 4K (8K with sliding window) so it's a mixed bag depending on what your doing, which makes sense for the size of the model, but there has been issues with .gguf support which should be fixed soon so gotta wait a bit longer to see how they fully perform on local hardware for people",2024-06-28 17:36:42.764000+00:00
Nix,"I have now tested both models in a lot of areas I usually throw models into to see how they perform knowledge-wise along with other stuff and here is my ranking:

Yi-Large > LLaMA-3-70B > Yi-1.5-34B > Gemma-2-27B > Gemma-2-9B > Yi-1.5-9B > LLaMA-3-8B

Gemma-2-9B being distilled from Gemma-2-27B makes a lot of sense why it performs so good, so there is a new under 10B model that is state of the art, even knowledge wise it performs shockingly well. Gemma-2-27B on the other hand feels like a great model, but in terms of knowledge it gets a lot of things wrong that models like Yi-1.5-34B don't get wrong. It is quite solid in coding and reasoning,  about as on par as Yi-1.5-34B, maybe a bit above in some areas, but imo Yi-1.5-34B with its fully open license, MUCH longer context length, and having more overall knowledge of the world, for me it beats out Gemma-2-27B. It formats amazingly and gives its answers in a well structured and sweet way, but it is lacking in other places (maybe from the LMSYS RL). For some tasks it could replace LLaMA-3-70B for sure, but a lot of tasks need the larger model for deeper depth of understanding and knowledge.

Since all modern LLMs are now trained on carefully crafted datasets like all listed above, it is now about size and other techniques along with diverse and clean data as mentioned before to allow these models to get better for their size.

Overall, the Gemma 2 models are quite powerful and will have their use cases for a lot of people, but for the 27B model, it just is not there for me, while the 9B model is the best under 9B model for me, but depending on how good fine-tunes are for it, I might stick with Yi-1.5-9B or LLaMA-3-8B",2024-06-29 06:47:07.290000+00:00
